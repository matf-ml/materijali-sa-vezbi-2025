{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rekurentne neuronske mreže"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U ovoj svesci sumirani su osnovni koncepti vezani za rekturentne neuronske mreže i podrška torch biblioteke u radu sa njima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/RNN.png'>\n",
    "<p style='text-align: right; color: gray; font-size: 10px;'> Slika je pozajmljena iz prezentacije Recurrent Neural Networks Momčila Vasiljevića, MDCS </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ono što je zajedničko za sve rekurentne neuronske mreže je da obrađuju sekvence podataka element po element. Na primer, mogu se obrađivati reči teksta sa ciljem da se predvidi naredna reč ili blok reči (takozvani zadatak dopune teksta, engl. text completition), cene akcija na berzi sa ciljem da se predvidi naredna vrednost i slično. Zato se o rekurentnim neuronskim mrežama obično priča sa aspekta vremenske dimenzije: u obradi u trenutku $t$ uzima se u obzir ulaz mreže $x_t$ i stanje mreže $s_{t-1}$ kojim se sumira ono što je mreža do tog trenutka obradila kako bi se generisao izlaz $o_t$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "SEED = 7\n",
    "# za determinističko izvršavanje sveske:\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jednostavna rekurentna neuronska mreža"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jednostavna rekurentna neuronska mreža je obična potpuno povezana mreža koja u trenutku $t$ na osnovu ulaza $x_t$ i prethodnog izlaza $o_{t-1}$ odlučuje o novom izlazu $o_t$. <img src='assets/simple_RNN.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sledećim kodom opisan je jedan prolaz kroz ovako definisanu rekurentnu neuronsku mrežu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dužinu sekvence ćemo zadati promenljivom `timesteps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ulazi u mrežu će nam biti vektori dužine `inuput_size`.  Dužina ovog vektora odgovara broju atributa (engl. features)  koje imamo na nivou pojedinačnih instanci. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrica svih ulaza će biti dimenzija `timesteps` x `input_size`. Inicijalizovaćemo je nasumičnim vrednostima.\n",
    "<img src='assets/sequence_data.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.random((timesteps, input_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izlazi mreže će biti vektori dužine `output_size`. Sa `output_t_prev` ćemo obeležavati vrednost izlaza za trenutak `t-1`, a sa `output_t` vrednost izlaza za trenutak `t`. Na početku će vektor prethodnih izlaza biti vektor nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_t_prev = np.zeros(output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovu rekurentnu neuronsku mrežu karakteriše matrica `U` koji povezuje trenutni ulaz `x_t` sa trenutnim izlazom `o_t` i matrica `V` koja povezuje trenutni izlaz `o_t` sa prethodnim izlazom `o_t_prev`. Ove matrice ćemo nasumično generisati. Generisaćemo i nasumični vektor slobodnih članova `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.random.random((output_size, input_size))\n",
    "V = np.random.random((output_size, output_size))\n",
    "\n",
    "b = np.random.random(output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/simple_RNN_unrolled.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jedan prolaz kroz mrežu u obradi sekvence `inputs` je opisan kodom ispod. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# izlazi mreze\n",
    "successive_outputs = []\n",
    "\n",
    "# za svaki ulaz u sekvenci\n",
    "for input_t in inputs:\n",
    "    \n",
    "    # kombinuje se tekuci ulaz input_t i prethodni izlaz output_t_prev i izračunava se novi izlaz\n",
    "    output_t = np.tanh(U @ input_t + V @ output_t_prev + b)\n",
    "    \n",
    "    # trenutni izlaz mreze treba uzeti u obzir prilikom obrade sledeceg ulaza \n",
    "    output_t_prev = output_t.copy()    \n",
    "    \n",
    "    # cuvamo izlaz mreze\n",
    "    successive_outputs.append(output_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niz svih izlaza je dužine koja odgovara dužini sekvence, preciznije oblika `input_size` x `output_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(successive_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(successive_outputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rekurentna neuronska mreža sa prenosom skrivenog stanja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kada se govori o rekurentnim neuronskim mrežama ponajčešće se misli na mreže koje imaju arhitekturu koja je prikazana na slici. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/RNN_unfolded.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Njome se u trenutku $t$ na osnovu ulaza $x_t$ i prethodnog stanja skrivenog sloja $h_{t-1}$ odlučuje o novom izlazu $o_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvo ćemo ponoviti deklaracije promenljivih. Njihovo značenje je i u kontekstu ove arhitetkure identično prethodnim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = 100\n",
    "input_size = 32 \n",
    "inputs = np.random.random((timestamps, input_size))\n",
    "output_size = 64 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veličinu skrivenog sloja mreže ćemo zadati dimenzijom `hidden_size`. Sa `h_t_prev` ćemo obeležavati vrednost skrivenog sloja za trenutak `t-1`, a sa `h_t` vrednost skrivenog sloja za trenutak `t`. Na početku treniranja `h_t_prev` će biti vektor nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_t_prev = np.zeros(hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovu rekurentnu neuronsku mrežu karakteriše matrica `U` sloja koji povezuje trenutni ulaz `x_t` sa trenutnom vrednošću skrivenog sloja `h_t`, matrica `V` koja povezuje stanje skrivenog sloja iz prethodnog trenutka `h_t_prev` i tekuće stanje `h_t`, i matrica `W` sloja kojom se povezuje skriveno stanje `h_t` sa izlazom `o_t`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.random.random((hidden_size, input_size))\n",
    "V = np.random.random((hidden_size, hidden_size))\n",
    "W = np.random.random((output_size, hidden_size))\n",
    "\n",
    "# vektori slobodnih clanova \n",
    "b1 = np.random.random(hidden_size)\n",
    "b2 = np.random.random(output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jedan prolaz kroz mrežu u obradi sekvence `inputs` je opisan kodom ispod. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# izlazi mreze\n",
    "successive_outputs = []\n",
    "\n",
    "# za svaki ulaz u sekvenci\n",
    "for input_t in inputs:\n",
    "    \n",
    "    # kombinuje se tekuci ulaz input_t i stanje skrivenog sloja mreze iz prethodnog koraka h_t_prev \n",
    "    # i izračunava se novo stanje skrivenog sloja \n",
    "    h_t = np.tanh(U @ input_t + V @ h_t_prev + b1)\n",
    "    \n",
    "    # izracuna se izlaz mreze\n",
    "    output_t= np.tanh(W @ h_t + b2)\n",
    "\n",
    "    # trenutne vrednosti skrivenog sloja mreze traba uzeti u obzir prilikom obrade sledeceg ulaza \n",
    "    h_t_prev = h_t.copy()    \n",
    "    \n",
    "    # cuvamo izlaz mreze\n",
    "    successive_outputs.append(output_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niz svih izlaza je dužine koja odgovara dužini sekvence, preciznije oblika `timestamps` x `output_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(successive_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(successive_outputs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svojom specifičnom strukturom, LSTM (engl. Long-Short Term Memory) ćelije nude rešenje za praćenje dugoročnih zavisnosti na nivou sekvenci koje zbog problema isčezavajućih gradijenata (praktično) nije bilo moguće sa stanradnim RNN ćelijama. \n",
    "\n",
    "Uz vrednosti skrivenog sloja ove ćelije imaju svoje interno stanje, ulaznu kapiju (engl. input gate), kapiju za zaboravljanje (engl. forget gate) i izlaznu kapiju (engl. output gate) kojima, redom, mogu da kontrolišu prisutnost informacija iz prethodnog stanja, njihovu selekciju i generisanje vrednosti koje će dalje propagirati. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/LSTM_cell_2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U trenutku $t$ na osnovu ulaza $x_t$, vrednosti skrivenog sloja $h_{t-1}$ i stanja $c_{t-1}$ prethodnog koraka obrade, treba odlučiti o novoj vrednosti skrivenog sloja $h_t$, stanja $c_t$ i izlaza $o_t$. \n",
    "\n",
    "Kapijom za zaboravljanje $f_t$ se kontroliše koliko informacija iz prethodnog stanja treba dalje propustiti. Na osnovu vrednosti matrica $W_f$ i $U_f$ i vektora slobodnih članova $b_f$ koje je karakterišu, izračunavaju se vrednosti vektora $f_t$ koje su u opsegu [0, 1]. Pokoordinatnim množenjem sa vrednošću $c_{t-1}$ dobijaju se filtrirane informacije stanja. Dalje se, na sličan način, izračunavaju vrednosti ulazne kapije $i_t$ i vrednosti izlazne kapije $o_t$. Ulaznom kapijom se filtrijaju informacije međustanja ćelije $\\tilde{c_t}$ koje treba dodati informacijama koje se filtrijaju kapijom zaboravljanja kako bi se dobilo novo stanje $c_t$. Nova vrednost skrivenog stanja se dobija na osnovu vrednosti izlazne kapije $o_t$ i novog stanja ćelije $c_t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/LSTM_math.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 100\n",
    "input_size = 32\n",
    "output_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametri za kapiju zaboravljanja\n",
    "W_f = np.random.random((output_size, input_size))\n",
    "U_f = np.random.random((output_size, output_size))\n",
    "b_f = np.random.random((output_size,))\n",
    "\n",
    "# parametri za ulazne kapije\n",
    "W_i = np.random.random((output_size, input_size))\n",
    "U_i = np.random.random((output_size, output_size))\n",
    "b_i = np.random.random((output_size,))\n",
    "\n",
    "# parametri za izlazne kapije\n",
    "W_o = np.random.random((output_size, input_size))\n",
    "U_o = np.random.random((output_size, output_size))\n",
    "b_o = np.random.random((output_size,))\n",
    "\n",
    "# parametri medjustanja\n",
    "W_c = np.random.random((output_size, input_size))\n",
    "U_c = np.random.random((output_size, output_size))\n",
    "b_c = np.random.random((output_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.randn(timesteps, input_size)\n",
    "\n",
    "# inicijalno stanje LSTM celije\n",
    "c = np.zeros((output_size,))\n",
    "h = np.zeros((output_size,))\n",
    "\n",
    "# izlazi mreze\n",
    "successive_outputs = []\n",
    "for input in inputs:\n",
    "    f = sigmoid(W_f @ input + U_f @ h + b_f)\n",
    "    i = sigmoid(W_i @ input + U_i @ h + b_i)\n",
    "    o = sigmoid(W_o @ input + U_o @ h + b_o)\n",
    "    c_tilda = np.tanh(W_c @ input + U_c @ h + b_c)\n",
    "    c = f * c + i * c_tilda\n",
    "    h = o * np.tanh(c)\n",
    "    successive_outputs.append(h)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU ćelije"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/GRU_cell.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU (engl. Gated-Recurent Units) ćelije predstavljaju modifikaciju LSTM ćelija objedinjavanjem kapije ulaza i kapije zaboravljanja u jednu kapiju ažuriranja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U praksi rad sa GRU ćelijama vodi do bržeg treniranja. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 100\n",
    "input_size = 32\n",
    "output_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametri za kapiju reset\n",
    "W_r = np.random.random((output_size, input_size))\n",
    "U_r = np.random.random((output_size, output_size))\n",
    "b_r = np.random.random((output_size,))\n",
    "\n",
    "# parametri za kapiju ažuriranja\n",
    "W_z = np.random.random((output_size, input_size))\n",
    "U_z = np.random.random((output_size, output_size))\n",
    "b_z = np.random.random((output_size,))\n",
    "\n",
    "# parametri medjustanja\n",
    "W_h = np.random.random((output_size, input_size))\n",
    "U_h = np.random.random((output_size, output_size))\n",
    "b_h = np.random.random((output_size,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.randn(timesteps, input_size)\n",
    "\n",
    "# inicijalno stanje GRU celije\n",
    "h = np.zeros((output_size,))\n",
    "\n",
    "# izlazi mreze\n",
    "successive_outputs = []\n",
    "for input in inputs:\n",
    "    z = sigmoid(W_z @ input + U_z @ h + b_z)\n",
    "    r = sigmoid(W_r @ input + U_r @ h + b_r)\n",
    "    h_tilda = np.tanh(W_h @ input + U_h @ (r * h) + b_h)\n",
    "    h = (1 - z) * h + z * h_tilda\n",
    "    successive_outputs.append(h)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odgovarajuća torch podrška"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U biblioteci `torch`, podrška je omogućena za rad sa jednostavnim rekurentnim neuronskim mrežama (RNN), LSTM mrežama i GRU slojevima. Za izračunavanja koja smo demonstrirali u uvodnim primerima unutar for petlje, biblioteka `torch` koristi klase `RNNCell`, `LSTMCell` i `GRUCell`. Ove klase su dizajnirane da obrađuju podatke organizovane u pakete sa strukturom `(timesteps, batch_size, N)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 100\n",
    "input_size = 32\n",
    "output_size = 64\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicijalizacija početnih stanja, često se koristi 0\n",
    "h = torch.zeros(batch_size, output_size)\n",
    "c = torch.zeros(batch_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer koriscenja LSTMCell klase\n",
    "lstm_cell = nn.LSTMCell(input_size=input_size, hidden_size=output_size) \n",
    "inputs = torch.randn(timesteps, batch_size, input_size) \n",
    "\n",
    "output = []\n",
    "for input_t in inputs:\n",
    "    h, c = lstm_cell(input_t, (h, c))\n",
    "    output.append(h)\n",
    "output = torch.stack(output, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pored ovih osnovnih klasa, modul `torch.nn` u biblioteci `torch` takođe uključuje klase `RNN`, `LSTM` i `GRU`. Ove klase omogućavaju izračunavanje svih skrivenih stanja sekvence unutar `forward` metoda, a takođe pružaju opciju za povezivanje višeslojnih rekurentnih neuronskih mreža, kako je ilustrovano na slici ispod."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/stacked_RNN.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broj slojeva može se kontrolisati pomoću parametra `num_layers` u konstruktorima ovih klasa. Dodatno, u konstruktoru je moguće izmeniti podrazumevanu strukturu paketića sa `(timesteps, batch_size, N)` u `(batch_size, timesteps, N)` aktiviranjem opcije `batch_first=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svaka od klasa `RNN`, `LSTM`, i `GRU` pruža dva rezultata nakon obrade podataka. Prvi rezultat predstavljaju izlazi iz poslednjeg sloja mreže (označeni kao $h_{10}$ i $h_{11}$ na slici), dok drugi uključuje skrivena stanja svakog sloja na kraju sekvence, što je na slici prikazano plavom bojom. Detaljnije objašnjenje i primere za svaku od ovih klasa možete pronaći u narednim odeljcima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN klasa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U [zvaničnoj dokumentaciji](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) možete videti da ova klasa vrši neznatno izmenjen račun u odnosu na metod koji smo opisali u uvodu. \n",
    "\n",
    "$h_t = tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{t-1} + b_{hh})$\n",
    "\n",
    "Ovo nema uticaj na definiciju modela, već samo povećava broj parametara koje on ima. Ovo je urađeno zbog biblioteke cuDNN koju torch koristi za ubrzavanje ovih izračunavanja. Slične razlike će biti prisutne i u svim ostalim slojevima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 100\n",
    "input_size = 32\n",
    "output_size = 64\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "model = nn.RNN(input_size, hidden_size=output_size, num_layers=1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(32, 64, batch_first=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broj parametara napravljenog modela je $32 \\cdot 64 + 64 + 64 \\cdot 64 + 64 = 6272$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6272\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN sloj daje dva izlaza: prvi je tenzor koji sadrži izlaze iz poslednjeg sloja mreže. Kada je parametar `batch_first` postavljen na `True`, ovaj tenzor će imati oblik `(batch_size, timesteps, hidden_size)`. Drugi izlaz predstavlja skrivena stanja posle obrade poslednjeg elementa u sekvenci i ima oblik `(num_layers, batch_size, hidden_size)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(batch_size, timesteps, input_size)\n",
    "model = nn.RNN(input_size, hidden_size=output_size, num_layers=3, batch_first=True)\n",
    "output, h_last = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: torch.Size([16, 100, 64])\n",
      "h_last: torch.Size([3, 16, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f\"output: {output.shape}\")\n",
    "print(f\"h_last: {h_last.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM klasa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izračunavanja koja ova klasa vrši su sledeća:\n",
    "\n",
    "$i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi})$\n",
    "\n",
    "$f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf})$\n",
    "\n",
    "$o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho})$\n",
    "\n",
    "$g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg})$\n",
    "\n",
    "$c_t = f_t \\circ c_{t-1} + i_t \\circ g_t$\n",
    "\n",
    "$h_t = o_t \\circ \\tanh(c_t)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = 100\n",
    "input_size = 32 \n",
    "output_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(32, 64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.LSTM(input_size=input_size, hidden_size=output_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svaka od matrica $W_{i\\_}$ je dimenzije `output_size` x `input_size`, svaka od matrica  $W_{h\\_}$ je dimenzije  `output_size` x `output_size` i svaki vektor slbodnih članova je dimenzije `output_size`. Ukupan broj parametara modela koji smo definisali je:\n",
    "\n",
    "4 x 64 x 32 + 4 x 64 x 64 + 8 x 64 = 25088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25088\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slično RNN sloju, prvi izlaz LSTM sloja kada je parametar `batch_first=True` aktiviran biće tenzor oblika `(batch_size, timesteps, hidden_size)`. Međutim, budući da LSTM sloj upravlja sa dva tipa skrivenih stanja—stanje ćelije i skriveno stanje—drugi izlaz će biti uređeni par tenzora. Svaki od ovih tenzora imaće oblik `(num_layers, batch_size, hidden_size)`, pri čemu jedan predstavlja stanje ćelije, a drugi skriveno stanje, oba nakon obrade poslednjeg elementa u sekvenci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: torch.Size([128, 100, 64])\n",
      "   h_n: torch.Size([3, 128, 64])\n",
      "   c_n: torch.Size([3, 128, 64])\n"
     ]
    }
   ],
   "source": [
    "model = nn.LSTM(input_size=input_size, hidden_size=output_size, num_layers=3, batch_first=True)\n",
    "timestamps = 100\n",
    "input_size = 32 \n",
    "output_size = 64\n",
    "batch_size = 128\n",
    "input = torch.randn(batch_size, timestamps, input_size)\n",
    "output, (h_n, c_n) = model(input)\n",
    "print(f'output: {output.shape}')\n",
    "print(f'   h_n: {h_n.shape}')\n",
    "print(f'   c_n: {c_n.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU ćelije"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izračunavanja koja ova klasa vrši su sledeća:\n",
    "\n",
    "$r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{t-1} + b_{hr})$\n",
    "\n",
    "$z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{t-1} + b_{hz})$\n",
    "\n",
    "$n_t = \\tanh(W_{in} x_t + b_{in} + r_t \\circ (W_{hn} h_{t-1} + b_{hn}))$\n",
    "\n",
    "$h_t = (1 - z_t) \\circ n_t + z_t \\circ h_{t-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = 100\n",
    "input_size = 32 \n",
    "inputs = np.random.random((timestamps, input_size))\n",
    "output_size = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(32, 64, batch_first=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GRU(input_size=input_size, hidden_size=output_size, batch_first=True)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broj parametara modela je: \n",
    "\n",
    "3 x 32 x 64 + 3 x 64 x 64 + 6 x 64 = 18816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18816\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izlazi GRU sloja isti su kao i izlazi RNN sloja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: torch.Size([128, 100, 64])\n",
      "h_last: torch.Size([3, 128, 64])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(batch_size, timesteps, input_size)\n",
    "model = nn.RNN(input_size, hidden_size=output_size, num_layers=3, batch_first=True)\n",
    "output, h_last = model(inputs)\n",
    "print(f'output: {output.shape}')\n",
    "print(f'h_last: {h_last.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Za dalje istraživanje:\n",
    "- [Ilustrovana pojašnjenja LSTM i GRU ćelija](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- Originalni rad u kojem su uvedene LSTM ćelije: [Long Short-Term Memory](http://www.bioinf.jku.at/publications/older/2604.pdf).\n",
    "- Originalni red u kojem su uvedene GRU ćelije: [Learning Phrase Representations using RNN Encoder–Decoder\n",
    "for Statistical Machine Translation](https://arxiv.org/pdf/1406.1078v3.pdf)\n",
    "- [Coursera, Deep Learning Specialization - Sequence Modeling (part 5)](https://www.coursera.org/specializations/deep-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
