{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch biblioteka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PyTorch** je Python biblioteka koja je jedna od najkorišćenijih biblioteka za duboko učenje. Slično kao i biblioteka numpy, pytorch biblioteka se zasniva na operacijama nad višedimenzionim nizovima. Za razliku od biblioteke numpy, pytorch podrža autmatsko računanje gradijenata, kao i ubrzavanje izračunavanja korišćenjem grafičkih kartica, što značajno olakšava i ubrzava optimizaciju neuronskih mreža. Na [ovom](https://pytorch.org/) linku se nalazi zvanična stranica biblioteke, a [ovde](https://pytorch.org/tutorials/beginner/basics/intro.html) se može pronaći koristan tutorijal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Višedimenzione nizove u biblioteci pytorch nazivamo tenzorima i operacije nad njima su vrlo slične operacijama iz biblioteke numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "X.shape = torch.Size([2, 3])\n",
      "X.dtype = torch.int64\n",
      "----\n",
      "X = tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "X.dtype = torch.float32\n",
      "----\n",
      "tensor([[ 0.9992,  1.0344, -1.9470],\n",
      "        [-0.2329, -1.4034, -0.5485]])\n",
      "Y.shape = torch.Size([2, 3])\n",
      "Y.dtype = torch.float32\n",
      "----\n",
      "X + Y = tensor([[1.9992, 3.0344, 1.0530],\n",
      "        [3.7671, 3.5966, 5.4515]])\n",
      "X * Y = tensor([[ 0.9992,  2.0687, -5.8410],\n",
      "        [-0.9318, -7.0168, -3.2912]])\n",
      "X @ Y.T = tensor([[ -2.7730,  -4.6853],\n",
      "        [ -2.5132, -11.2399]])\n",
      "2^X = tensor([[ 2.,  4.,  8.],\n",
      "        [16., 32., 64.]])\n",
      "sin(X) = tensor([[ 0.8415,  0.9093,  0.1411],\n",
      "        [-0.7568, -0.9589, -0.2794]])\n",
      "----\n",
      "X.sum() = tensor(21.)\n",
      "X.sum(dim=0) = tensor([5., 7., 9.])\n",
      "X.sum(dim=1) = tensor([ 6., 15.])\n"
     ]
    }
   ],
   "source": [
    "# pravljenje tenzora od niza\n",
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print('X =', X)\n",
    "print('X.shape =', X.shape)\n",
    "print('X.dtype =', X.dtype)\n",
    "\n",
    "print('----')\n",
    "# promena tipa podataka u tenzoru\n",
    "X = X.to(torch.float32)\n",
    "# X = X.float()\n",
    "print('X =', X)\n",
    "print('X.dtype =', X.dtype)\n",
    "\n",
    "print('----')\n",
    "# pravljenje tenzora sa podacima iz normalne raspodele\n",
    "Y = torch.randn_like(X)\n",
    "# Y = torch.randn(X.shape())\n",
    "print(Y)\n",
    "print('Y.shape =', Y.shape)\n",
    "print('Y.dtype =', Y.dtype)\n",
    "\n",
    "print('----')\n",
    "# aritmetičke operacije\n",
    "print('X + Y =', X + Y)\n",
    "print('X * Y =', X * Y)\n",
    "print('X @ Y.T =', X @ Y.T)\n",
    "print('2^X =', 2 ** X)\n",
    "print('sin(X) =', torch.sin(X))\n",
    "\n",
    "print('----')\n",
    "print('X.sum() =', X.sum())\n",
    "print('X.sum(dim=0) =', X.sum(dim=0))\n",
    "print('X.sum(dim=1) =', X.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatsko diferenciranje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatsko diferenciranje nam je dostupno kroz paket `torch.autograd`. Prilikom računanja sa tenzorima, pytorch pamti graf izračunavanja što joj omogućava da primenom pravila o izvodu složene funkcije, kretanjem u nazad kroz graf, izračuna gradijente tenzora čiji je parametar `requiers_grad` postavljen na `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.grad = tensor(6.)\n",
      "Y.grad = tensor(3.)\n",
      "Z.grad = None\n",
      "-------\n",
      "Višestruko računanje gradijenta:\n",
      "X.grad = tensor(2.)\n",
      "X.grad = tensor(5.)\n",
      "Gradovi se u tenzoru sabiraju!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15660/3410228716.py:8: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1724788960438/work/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  print('Z.grad =', Z.grad) # None\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(1.0, requires_grad=True)\n",
    "Y = torch.tensor(2.0, requires_grad=True)\n",
    "Z = torch.tensor(3.0)\n",
    "Z = X * Y * Z\n",
    "Z.backward() # računanje gradijenta\n",
    "print('X.grad =', X.grad)\n",
    "print('Y.grad =', Y.grad)\n",
    "print('Z.grad =', Z.grad) # None\n",
    "print('-------')\n",
    "print('Višestruko računanje gradijenta:')\n",
    "X = torch.tensor(1.0, requires_grad=True)\n",
    "l = X**2\n",
    "l.backward()\n",
    "print('X.grad =', X.grad) # X.grad = 2.0\n",
    "l = X**3\n",
    "l.backward()\n",
    "print('X.grad =', X.grad) # X.grad = 5.0\n",
    "print('Gradovi se u tenzoru sabiraju!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Možemo primetiti da se gradijenti sabiraju svaki put kada računamo izvod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradijent funkcije srednje kvadratne greške linearne regresije nad slučajnim podacima se može izračunati na sledeći način"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.grad.shape = torch.Size([1, 8])\n",
      "b.grad.shape = torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(32, 8)\n",
    "W = torch.randn(1, 8, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "Y = torch.randn(32, 1)\n",
    "Z = W @ X.T + b\n",
    "L = ((Y - Z) ** 2).mean()\n",
    "L.backward()\n",
    "print('W.grad.shape =', W.grad.shape)\n",
    "print('b.grad.shape =', b.grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradijentni spust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uz automatsko diferenciranje, biblioteka PyTorch ima implementirane različite algoritme gradijentnog spusta. Svi oni se nalaze u okviru `torch.optim` paketa gde su implementirani koraci gradijentnog spusta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovde možemo videti primer optimizacije funkcije $f(x, y) = |x| + |y|$ sa 5 koraka gradijentnog spusta sa stopom učenja 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "step = 0\n",
      "x = 1.5 y = 3.0\n",
      "----\n",
      "step = 1\n",
      "x = 0.5 y = 2.0\n",
      "----\n",
      "step = 2\n",
      "x = -0.5 y = 1.0\n",
      "----\n",
      "step = 3\n",
      "x = 0.5 y = 0.0\n",
      "----\n",
      "step = 4\n",
      "x = -0.5 y = 0.0\n"
     ]
    }
   ],
   "source": [
    "def f(x, y):\n",
    "    return x.abs() + y.abs()\n",
    "\n",
    "LEARNING_RATE = 1\n",
    "NUMBER_OF_ITERATIONS = 5\n",
    "\n",
    "x = torch.tensor(2.5, requires_grad=True)\n",
    "y = torch.tensor(4.0, requires_grad=True)\n",
    "\n",
    "# pravljenje optimizatora\n",
    "optimizer = torch.optim.SGD([x, y], lr=LEARNING_RATE)\n",
    "\n",
    "for step in range(NUMBER_OF_ITERATIONS):\n",
    "    l = f(x, y)\n",
    "\n",
    "    optimizer.zero_grad() # postavljanje gradijenata na nulu\n",
    "    l.backward() # računanje gradijenata\n",
    "    optimizer.step() # optimizacija\n",
    "    print('----')\n",
    "    print('step =', step)\n",
    "    print('x =', x.item(), 'y =', y.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rad sa podacima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U biblioteci PyTorch posotje dve korinse klase za rad sa podacima, obe u okviru paketa `torch.utils.data`:\n",
    "\n",
    "- `Dataset` - klasa koju koristimo za učitavanje podataka. Cilj ove klase je da se pomoću nje može dobiti jedna instanca iz skupa podataka. \n",
    "- `Datloader` - klasa koja iz skupa podataka predstavljenog `Dataset` klasom izdvaja delove nad kojim će se vršiti jedan korak stohastičnog gradijentnog spusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape = torch.Size([32, 2])\n",
      "labels.shape = torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, IterableDataset\n",
    "\n",
    "class RandomDataset_v1(Dataset):\n",
    "    def __init__(self, size=1000):\n",
    "        super().__init__()\n",
    "        self.data = torch.randn(size, 2)\n",
    "        self.labels = torch.randn(size, 1)\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "dataset1 = RandomDataset_v1()\n",
    "\n",
    "class RandomDataset_v2(IterableDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for _ in range(1000):\n",
    "            yield torch.randn(2), torch.randn(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "dataset2 = RandomDataset_v2()\n",
    "\n",
    "X = torch.randn(1000, 2)\n",
    "Y = torch.randn(1000, 1)\n",
    "dataset3 = TensorDataset(X, Y)\n",
    "        \n",
    "\n",
    "dataloader = DataLoader(dataset1, batch_size=32, shuffle=True, num_workers=4)\n",
    "# dataloader = DataLoader(dataset2, batch_size=32, num_workers=4) # shuffle ne radi za IterableDataset\n",
    "# dataloader = DataLoader(dataset3, batch_size=32, shuffle=True, num_workers=4)\n",
    "for data, labels in dataloader:\n",
    "    print('data.shape =', data.shape)\n",
    "    print('labels.shape =', labels.shape)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Više o paketu `torch.utils.data` možete pronaći u [zvaničnoj dokumentaciji](https://pytorch.org/docs/stable/data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podrška za neuronske mreže"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Velika većina funkcionalnosti koje će nam biti potrebne za definicije neuronskih mreže se nalaze u okviru paketa `torch.nn`. Na primer ukoliko želimo da izvršimo linearnu transformaciju atributa, za to možemo koristiti klasu `torch.nn.Linear`, a za računanje srednje kvadratne greške možemo koristiti klasu `nn.MSELoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n",
      "loss = tensor(1.8713, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "x = torch.randn(32, 8)\n",
    "y = torch.randn(32, 1)\n",
    "linear = nn.Linear(8, 1)\n",
    "\n",
    "print(linear(x).shape)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "print('loss =', loss(linear(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definisanje modela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definisanje modela u biblioteci PyTorch se najčešće radi nasleđivanjem klase `nn.Module` i implemenitranjem metode `forward` koja se poziva korišćenjem () sintakse. Pored klase  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(\n",
      "  (linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "torch.Size([32, 1])\n",
      "tensor(0.8649, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "x = torch.randn(32, 8)\n",
    "y = torch.randn(32, 1)\n",
    "\n",
    "model = LinearRegression(8, 1)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "print(model)\n",
    "print(model(x).shape)\n",
    "print(loss(model(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcionalni pristup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za svaku klasu koju koristimo za neko izračunavanje (kao što su `nn.Linear` ili `nn.MSELoss`) postoji funckija u okviru paketa `torch.nn.functional` koju možemo koristiti za to izračunavanje. Ovo može biti posebno korisno ako je potrebno raditi neke nestandardne operacije koje liče na ove već postojeće."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "torch.Size([32, 1])\n",
      "tensor(5.4862, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.linear(x, self.weights, self.bias)\n",
    "\n",
    "x = torch.randn(32, 8)\n",
    "y = torch.randn(32, 1)\n",
    "\n",
    "model = LinearRegression(8, 1)\n",
    "\n",
    "print(model)\n",
    "print(model(x).shape)\n",
    "print(F.mse_loss(model(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rad sa grafičkim karticama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Većina operacija koje se koriste u mašinskom učenju mogu se efikasno paralelizovati korišćenjem grafičkih kartica. Sve biblioteke mašinkog učenja iz ovog razloga moraju imati podršku za korišćenje grafičkih kartica. U biblioteci PyTorch svi tenzori imaju atribut `device` koji naglašava da li se on nalazi u radnoj memoriji računara ili u radnoj memoriji grafičke kartice. Kako bi se neka operacija između dva tenzora izvršila oba tenzora moraju imati isti atribut `device` i u zavisnosti od toga gde se nalaze, operaciju će izvršiti grafička kartica, odnosno procesor. Podrazumevano svi tenzori imaju `device` postavljen na `cpu`, a metodom `.to('cuda')` možemo ga prebaciti na grafičku karitcu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available() # test da li je grafička kartica dostupna\n",
    "# torch.cuda.device_count() # broj grafičkih kartica\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "\n",
    "X = torch.randn(32, 8).to(device)  # ukoliko je grafička kartica dostupna, tenzor će biti na njoj\n",
    "Y = torch.randn(32, 1).to(device)  # ukoliko je grafička kartica dostupna, tenzor će biti na njoj\n",
    "linear = nn.Linear(8, 1).to(device) # ukoliko je grafička kartica dostupna, težine modela će biti na njoj\n",
    "print('X.device =', X.device)\n",
    "print('Y.device =', Y.device)\n",
    "print('linear.device =', linear.weight.device)\n",
    "print('linear.weight.device =', linear.weight.device)\n",
    "print('linear.bias.device =', linear.bias.device)\n",
    "print('linear(X).device =', linear(X).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
